===Cybersecurity course===

====Lesson 1: Introduction====

Classifying threats:

STRIDE - Threat model:
* Spoofing: Someone illegally accessing a system using another user's authentication information.
* Tampering: Detects unauthorized changes made to persistent data.
* Repudiation: Trace user operations to provide evidence of what has happened in case of a breach.
* Information Disclosure: Exposure of information to unauthorized individuals.
* Denial of Service: The server or service is made temporarily unaivalable.
* Elevation of Privilege: An unprivileged user finds a way to gain sufficient privileges to compromise the system.

DREAD - Risk assessment model:
* Damage
* Reproducibility
* Exploitability
* Affected Users
* Discoverability

Top 10 flaws (src: https://www.computer.org/cms/CYBSI/docs/Top-10-Flaws.pdf):

*Offload security functions from server to client.
**When untrusted clients send data to yout system or perform a computation on its behalf, the data sent must be assumed to be compormised until proven otherwise.
**Design a software system under the ssumption that components running on any platform whose integrity can't be attested are inherently non trustable.
**Protect sensitive information or intellectual property with obfuscation or anti-debugging, don't use the same shared secret or other cryptographic material on all the clients.
** Make sure all data received from an untrusted client are validated before processing.
** Be sure to consider the context where code will be executed, where data will go, and where data entering 
your system comes from.

*Use an authentiction mechanism that cannot be bypassed or tampered with.
**Prevent an entity from gaining access to a system or service without first authenticating. Once a user 
has been authenticated, a securely designed system should also prevent that user from changing identity without re-authentication. 
**Multi-factor authentication: Require multiple distinct factors to prove your identity.
**Credentials must not be easy to forge (e.g. a token created from the user name and more evident information).
**Authentication system should provide a mechanism requiring re-authentication after a period of inactivity or prior to critical operations.
**Asking users to frequently re-enter their password can be damaging to security, as it trains peopleâ€™s muscle memory to enter their password every time they see a prompt and sets them up as easy phishing targets.
**Correctly store passwords and password associations to users. 
**It's most preferable to have a single method or component responsible for authenticating users, serving as a "choke point" to avoid potential bypass.

*Authorize after you authenticate
**Authorization depends not only on the privileges associated wth an authenticated user, but also on the context of the request. Also, the time of the request and the location of the requesting user may both need to be taken into account.
**For particularly sensistive operations, authorization may need to invoke authentication.
**As a common infrastructure should be responsible for authenticating users, so too should common infrastructure be re-used for conducting authorization checks.

*Strictly separate data and control instructions, never proces control instructions received from untrusted sources.
**Lack of strict separation between data and code often leads to untrusted data controlling the execution flow of a software system.
**If software assembles a string in a parseable language by combining untrusted data with trusted control instructions, injection vulnerabilities arise if the untrusted data are insufficiently validated or escaped. In that situation, an attacker may be able to supply data crafted such that when the resulting expression is processed, parts of the data are parsed and interpreted as control (rather than uninterpreted data, as intended).
**Examples of such vulnerabilities include SQL query injection, cross-site JavaScript injection, and shell command injection.
**At lower levels, software platforms can utilize 
hardware capabilities to enforce separation of 
code and data (e.g. memory access permissions marking memory that only contains non-executable data, and executable data marked as immutable at runtime).
**When designing languages, compilers, virtual 
machines, parsers and related pieces of infrastructure, consider control-flow integrity and segregation of control and potentially untrusted data as important design goals. 
**When designing APIs (both general-purpose or public interfaces as well as those that are domain or application-specific), avoid exposing methods or endpoints that consume strings in languages that embed both control and data. 
**When designing applications that rely on existing APIs, avoid APIs that mingle data and control information in their parameters, especially when those parameters are strings. If there is no choice, encapsulate the injection-prone interface and expose its functionality through a higher level API enforcing strict segregation between control statements and potentially untrusted data.
**Validate data as full as possible before transform it into code:
***Eval functions: Could let the attacker execute arbitrary code.
***Query languages: Avoid injection vulnerabilities and code that constructs queries based on ad-hoc string concatenation.
***Exposed reflection: Language that allows reflectively inspect and manipulate objects could be vulnerable (e.g. to marshall and unmarshall objects, or invoke methods). Consider alternatives like code-generation at build/compile time, etc.

*Define an approach that ensures all data are explicitily validated
**Design software systems to ensure that comprehensive data validation actually takes place and all assumptions about data have been validated when they are used.
**Design or use centralized validation mechanisms to ensure all data entering a system are appropiatelly validated. 
**Transform data into a canonical form before performing actual syntactic or semantic validation, ensuring validation cannot be bypassed by supplying inputs that are encoded in a transport encoding or in a possibly invalid non-canonical form.
**Use common libraries of validation primitives, e.g. well formed URLs, email addresses, etc. Whitelisting validation better than blacklisting validation.
**Input validation requirements are often state-dependent, so design the protocol implementation's input validation component to be itself state-aware.
**Explicitly re-validate assumptions "nearby" code that relies on them. Liberal use of precondition checks in the entry points of software modules and components is highly recommended as re-validation for entries from upper layers.
***Protects against vulnerabilities that arise from insufficient input validation in a higher layer or from additional data-flows that were not considered during the initial security design.
***Permits local reasoning about the correctness of a component.
**Use implementatnion-language-level types to capture assumptions about data validity.

*Use cryptography correctly
**Avoid to roll own cryptographic algorithms or implementations. Use standard algorithms and libraries preferably.
**Misuse of libraries and algorithms. Choose the right algorithm and library for your needs.
**Poor key management. Avoid hard-coding keys on software, don't fail to allow for the revocation and/or rotation of keys, don't use weak cryptographic keys and weak distribution mechanisms.
**Use of not random randomness. Don't be confused between statistical randomness and cryptographic randomnes and don't re-use the random numbers.
**Failure to centralize cryptography. Cryptographic algorithms often don't interact nicely.
**Failure to allow for algorithm adaptation and evolution. Make your system flexible and allow future changes.

*Identify sensitive data and how they should be handled.
**Sensitive data are not always user-generated, also can be computed from scratch, coming from external sensors, cryptographic material and Personally Idenitifiable Information (PII). Creating a policy that expicitly identifies different levels of classification is the first step in handling data appropiately.
**Not all data protection requirements are equal: for some data confidentiality is critical, for other types availability is critical, in other cases integrity is most important, etc.
**A designer should also consider include access control mechanisms, cryptography to preserve data confidentiality or integrity, and redundancy and backups to preserve data availability.
**As data sets transit between systems, they may cross multiple trust boundaries, so identify these boundaries and rectify them with data protection policies is an essential design activity.
**Revisite and revise data protection policies and their design implications.

*Always consider the users
**All security-related mechanisms must be designed in a manner that makes it easy to deploy, configure, use and update the system securely.
**Take in consideration the users physical abilities, cultural biases, habits and idiosyncrasies of the intended users of the systems, it will impact its overall security stance.
**Assumptions about the sophistication or security knowledge of users are bound to be incorrect some percentages of the time.
**Take into account that authenticated and authorized users can also be attackers.
**Secure by default (make the easiest and most common usage scenario secure).
**Consider all relevant stakeholders (also collateral damage to other users data security).

*Understand how integrating external components changes your attack surface.
**This involves external or third party software in form of binaries, libraries, source code and APIs.
**Whenever possible, reuse tried-and-true pieces of previously tested and validated software.
**The system's threat model is a representation of the security posture of the system when all possible threats are taken into consideration, their mitigations established, and the vulnerabilities identified.
**Assume that incoming external components are not be trusted until appropiate security controls have been applied, in order to align the component's attack surface and security policy with ones that meet your requirements.
**Isolate external components as much as your required functionality permits (using containers, sandboxes, and drop privileges before entering uncontrolled code).
**Configure external components to enable only the functionality you intend to use.
**Consider how the not intended to use functionality changes your security posture and increases the security you must implement to account the change.
**If the security of the external component can not be configured to be aligned to our security goals, find another library or document the risk acceptance and inform stakeholders.
**Validate provenance and integrity of the external component using cryptographically trusted hashes, signatures, etc. and verify the downloaded source.
**Follow sources that tracks or publishes security-related information regarding the consumed external resources (mailing lists, VCE databases, etc.)
**Maintain and inform of an up-to-date list of consumed external components, and check if those are the latest know-secure versions of each software.
**Authenticate data flows between your system and external components.
**Verify and understand the default configuration of the external component.
**Document everything.
**Design for flexibility, in order to make the external components easily replaceable.

*Be flexible when considering future changes to objects and actors.
**Software security must be designed for change, consider the security implications for future changes to objects and actors.
**Any deployed system can eventually come under attack and potentially be compromised.
**The environment and conditions under whiche the system exists will also change.
**Design for secure updates. It is easier to upgrade small pieces of a system than huge blobs, ensuring that the security implications of the upgrade are well understood and controlled. Verify the integrity and provenance of upgrade package.
**Design for security properties changing over time; for example, when code is updated. 
**Design with the ability to isolate or toggle functionality. It should be possible to turn off compromised parts of the system, or to turn on performance-affecting mitigations, should the need arise.
**Design for changes to objects intended to be kept secret. The system should be prepared to have secrets replaced at any time and at all levels of the system.
***Secure way for users to change their own passwords, including disallowing the change until the old password has been succesfully presented by the user.
***Carefully considering any kind of "password recovery" mechanisme (e.g. reset a password instead of provide the password in clear text).
***Secure and efficient way to replace certificates, SSH keys, etc proviing clear and explicit logs of those events in a forensically verifiable way.
***Understanding how the key change affects data stored at rest.
**Design for changes in the security properties of components beyond your control. An external component's security properties or related characteristics may change over time. In these cases it is important to design "agility", the capability to change layers and alogirthms, as needed into the system.
**Design for changes to entitlements. The system must have a way to revoke access to areas when a user no longer has a need to access them. The access to critical system components should be regularly reviewed to confirm that those individuals with access still require that level of access.
